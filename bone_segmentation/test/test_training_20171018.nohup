Using TensorFlow backend.
./lib/pre_processing.py:67: RuntimeWarning: invalid value encountered in divide
  imgs_normalized[i] = ((imgs_normalized[i] - np.min(imgs_normalized[i])) / (np.max(imgs_normalized[i])-np.min(imgs_normalized[i])))*255
1

train images/masks shape:
(14, 1, 565, 565)
train images range (min-max): 0.0078431372549 - 1.0
train masks are within 0-1

(14, 1, 565, 565)
(14, 1, 565, 565)
48
48
patches per full image: 600
1

train PATCHES images/masks shape:
(8400, 1, 48, 48)
train PATCHES images range (min-max): 0.0078431372549 - 1.0
./src/pelvis_training.py:66: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor("ac..., inputs=Tensor("in...)`
  model = Model(input=inputs, output=conv7)
Check: final output of the network:
(None, 2304, 2)
./src/pelvis_training.py:191: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.
  model.fit(patches_imgs_train, patches_masks_train, nb_epoch=N_epochs, batch_size=batch_size, verbose=2, shuffle=True, validation_split=0.1, callbacks=[checkpointer])
Train on 7560 samples, validate on 840 samples
Epoch 1/150
2017-10-17 14:11:02.369044: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-17 14:11:02.369059: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-17 14:11:02.369077: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-10-17 14:11:02.369079: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-17 14:11:02.369082: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Epoch 00000: val_loss improved from inf to 0.91037, saving model to ./test/test_best_weights.h5
676s - loss: 0.6334 - acc: 0.6690 - val_loss: 0.9104 - val_acc: 0.0000e+00
Epoch 2/150
Epoch 00001: val_loss improved from 0.91037 to 0.80206, saving model to ./test/test_best_weights.h5
681s - loss: 0.5876 - acc: 0.6857 - val_loss: 0.8021 - val_acc: 0.0000e+00
Epoch 3/150
Epoch 00002: val_loss improved from 0.80206 to 0.76768, saving model to ./test/test_best_weights.h5
681s - loss: 0.5822 - acc: 0.6857 - val_loss: 0.7677 - val_acc: 0.0000e+00
Epoch 4/150
Epoch 00003: val_loss improved from 0.76768 to 0.72916, saving model to ./test/test_best_weights.h5
681s - loss: 0.5781 - acc: 0.6857 - val_loss: 0.7292 - val_acc: 0.0000e+00
Epoch 5/150
Epoch 00004: val_loss improved from 0.72916 to 0.69906, saving model to ./test/test_best_weights.h5
673s - loss: 0.5739 - acc: 0.6857 - val_loss: 0.6991 - val_acc: 0.0000e+00
Epoch 6/150
Epoch 00005: val_loss did not improve
668s - loss: 0.5695 - acc: 0.7127 - val_loss: 0.7004 - val_acc: 0.0000e+00
Epoch 7/150
Epoch 00006: val_loss improved from 0.69906 to 0.69415, saving model to ./test/test_best_weights.h5
665s - loss: 0.5660 - acc: 0.7316 - val_loss: 0.6942 - val_acc: 0.8576
Epoch 8/150
Epoch 00007: val_loss improved from 0.69415 to 0.69373, saving model to ./test/test_best_weights.h5
657s - loss: 0.5639 - acc: 0.7393 - val_loss: 0.6937 - val_acc: 0.8776
Epoch 9/150
Epoch 00008: val_loss did not improve
658s - loss: 0.5622 - acc: 0.7455 - val_loss: 0.6939 - val_acc: 0.8763
Epoch 10/150
Epoch 00009: val_loss did not improve
654s - loss: 0.5621 - acc: 0.7489 - val_loss: 0.6953 - val_acc: 0.8533
Epoch 11/150
Epoch 00010: val_loss did not improve
655s - loss: 0.5603 - acc: 0.7507 - val_loss: 0.6945 - val_acc: 0.8572
Epoch 12/150
Epoch 00011: val_loss improved from 0.69373 to 0.69369, saving model to ./test/test_best_weights.h5
657s - loss: 0.5602 - acc: 0.7516 - val_loss: 0.6937 - val_acc: 0.9119
Epoch 13/150
Epoch 00012: val_loss improved from 0.69369 to 0.69347, saving model to ./test/test_best_weights.h5
658s - loss: 0.5594 - acc: 0.7556 - val_loss: 0.6935 - val_acc: 0.9301
Epoch 14/150
Epoch 00013: val_loss improved from 0.69347 to 0.69321, saving model to ./test/test_best_weights.h5
656s - loss: 0.5598 - acc: 0.7541 - val_loss: 0.6932 - val_acc: 0.9887
Epoch 15/150
Epoch 00014: val_loss did not improve
656s - loss: 0.5608 - acc: 0.7518 - val_loss: 0.6942 - val_acc: 0.8576
Epoch 16/150
Epoch 00015: val_loss did not improve
656s - loss: 0.5586 - acc: 0.7572 - val_loss: 0.6938 - val_acc: 0.9097
Epoch 17/150
Epoch 00016: val_loss did not improve
656s - loss: 0.5581 - acc: 0.7579 - val_loss: 0.6933 - val_acc: 0.9444
Epoch 18/150
Epoch 00017: val_loss did not improve
656s - loss: 0.5579 - acc: 0.7589 - val_loss: 0.6935 - val_acc: 0.9297
Epoch 19/150
Epoch 00018: val_loss did not improve
657s - loss: 0.5581 - acc: 0.7587 - val_loss: 0.6937 - val_acc: 0.9219
Epoch 20/150
Epoch 00019: val_loss improved from 0.69321 to 0.69319, saving model to ./test/test_best_weights.h5
656s - loss: 0.5598 - acc: 0.7535 - val_loss: 0.6932 - val_acc: 0.9935
Epoch 21/150
Epoch 00020: val_loss did not improve
656s - loss: 0.5581 - acc: 0.7548 - val_loss: 0.6933 - val_acc: 0.9466
Epoch 22/150
Epoch 00021: val_loss improved from 0.69319 to 0.69317, saving model to ./test/test_best_weights.h5
656s - loss: 0.5574 - acc: 0.7603 - val_loss: 0.6932 - val_acc: 0.9952
Epoch 23/150
Epoch 00022: val_loss did not improve
655s - loss: 0.5584 - acc: 0.7591 - val_loss: 0.6935 - val_acc: 0.9288
Epoch 24/150
Epoch 00023: val_loss did not improve
655s - loss: 0.5572 - acc: 0.7608 - val_loss: 0.6934 - val_acc: 0.9306
Epoch 25/150
Epoch 00024: val_loss did not improve
655s - loss: 0.5615 - acc: 0.7483 - val_loss: 0.6962 - val_acc: 0.8342
Epoch 26/150
Epoch 00025: val_loss did not improve
656s - loss: 0.5572 - acc: 0.7590 - val_loss: 0.6938 - val_acc: 0.9102
Epoch 27/150
Epoch 00026: val_loss did not improve
656s - loss: 0.5586 - acc: 0.7564 - val_loss: 0.6932 - val_acc: 0.9900
Epoch 28/150
Epoch 00027: val_loss did not improve
656s - loss: 0.5614 - acc: 0.7481 - val_loss: 0.7077 - val_acc: 0.4570
Epoch 29/150
Epoch 00028: val_loss did not improve
655s - loss: 0.5564 - acc: 0.7625 - val_loss: 0.6933 - val_acc: 0.9696
Epoch 30/150
Epoch 00029: val_loss did not improve
656s - loss: 0.5558 - acc: 0.7627 - val_loss: 0.7110 - val_acc: 0.0655
Epoch 31/150
Epoch 00030: val_loss did not improve
656s - loss: 0.5567 - acc: 0.7618 - val_loss: 0.6939 - val_acc: 0.9076
Epoch 32/150
Epoch 00031: val_loss did not improve
655s - loss: 0.5561 - acc: 0.7631 - val_loss: 0.6933 - val_acc: 0.9852
Epoch 33/150
Epoch 00032: val_loss did not improve
655s - loss: 0.5550 - acc: 0.7661 - val_loss: 0.6933 - val_acc: 0.9635
Epoch 34/150
Epoch 00033: val_loss did not improve
655s - loss: 0.5564 - acc: 0.7638 - val_loss: 0.6934 - val_acc: 0.9253
Epoch 35/150
Epoch 00034: val_loss did not improve
656s - loss: 0.5551 - acc: 0.7670 - val_loss: 0.6932 - val_acc: 0.9939
Epoch 36/150
Epoch 00035: val_loss did not improve
655s - loss: 0.5574 - acc: 0.7610 - val_loss: 0.6932 - val_acc: 0.9891
Epoch 37/150
Epoch 00036: val_loss did not improve
654s - loss: 0.5568 - acc: 0.7607 - val_loss: 0.6941 - val_acc: 0.9041
Epoch 38/150
Epoch 00037: val_loss improved from 0.69317 to 0.69315, saving model to ./test/test_best_weights.h5
655s - loss: 0.5557 - acc: 0.7645 - val_loss: 0.6932 - val_acc: 0.9978
Epoch 39/150
Epoch 00038: val_loss did not improve
655s - loss: 0.5569 - acc: 0.7615 - val_loss: 0.6932 - val_acc: 0.9744
Epoch 40/150
Epoch 00039: val_loss did not improve
656s - loss: 0.5570 - acc: 0.7593 - val_loss: 0.6932 - val_acc: 0.9905
Epoch 41/150
Epoch 00040: val_loss did not improve
656s - loss: 0.5586 - acc: 0.7535 - val_loss: 0.6932 - val_acc: 0.9948
Epoch 42/150
Epoch 00041: val_loss did not improve
656s - loss: 0.5550 - acc: 0.7680 - val_loss: 0.6932 - val_acc: 0.9948
Epoch 43/150
Epoch 00042: val_loss did not improve
656s - loss: 0.5586 - acc: 0.7553 - val_loss: 0.6933 - val_acc: 0.9891
Epoch 44/150
Epoch 00043: val_loss did not improve
655s - loss: 0.5543 - acc: 0.7686 - val_loss: 0.6932 - val_acc: 0.9948
Epoch 45/150
Epoch 00044: val_loss did not improve
655s - loss: 0.5531 - acc: 0.7710 - val_loss: 0.6932 - val_acc: 0.9922
Epoch 46/150
Epoch 00045: val_loss did not improve
656s - loss: 0.5566 - acc: 0.7609 - val_loss: 0.6932 - val_acc: 0.9978
Epoch 47/150
Epoch 00046: val_loss did not improve
655s - loss: 0.5549 - acc: 0.7665 - val_loss: 0.6932 - val_acc: 0.9978
Epoch 48/150
Epoch 00047: val_loss improved from 0.69315 to 0.69315, saving model to ./test/test_best_weights.h5
655s - loss: 0.5554 - acc: 0.7670 - val_loss: 0.6932 - val_acc: 0.9978
Epoch 49/150
Epoch 00048: val_loss improved from 0.69315 to 0.69315, saving model to ./test/test_best_weights.h5
654s - loss: 0.5575 - acc: 0.7586 - val_loss: 0.6931 - val_acc: 0.9996
Epoch 50/150
Epoch 00049: val_loss did not improve
655s - loss: 0.5595 - acc: 0.7522 - val_loss: 0.7759 - val_acc: 0.0000e+00
Epoch 51/150
Epoch 00050: val_loss did not improve
655s - loss: 0.5543 - acc: 0.7691 - val_loss: 0.6933 - val_acc: 0.9709
Epoch 52/150
Epoch 00051: val_loss did not improve
655s - loss: 0.5598 - acc: 0.7516 - val_loss: 0.6937 - val_acc: 0.9128
Epoch 53/150
Epoch 00052: val_loss did not improve
655s - loss: 0.5562 - acc: 0.7596 - val_loss: 0.6931 - val_acc: 0.9996
Epoch 54/150
Epoch 00053: val_loss did not improve
655s - loss: 0.5596 - acc: 0.7512 - val_loss: 0.6936 - val_acc: 0.9284
Epoch 55/150
Epoch 00054: val_loss did not improve
655s - loss: 0.5547 - acc: 0.7652 - val_loss: 0.6932 - val_acc: 0.9961
Epoch 56/150
Epoch 00055: val_loss did not improve
656s - loss: 0.5524 - acc: 0.7740 - val_loss: 0.6932 - val_acc: 0.9913
Epoch 57/150
Epoch 00056: val_loss did not improve
657s - loss: 0.5582 - acc: 0.7595 - val_loss: 0.6932 - val_acc: 0.9974
Epoch 58/150
Epoch 00057: val_loss did not improve
657s - loss: 0.5598 - acc: 0.7487 - val_loss: 0.6936 - val_acc: 0.9136
Epoch 59/150
Epoch 00058: val_loss did not improve
657s - loss: 0.5557 - acc: 0.7599 - val_loss: 0.6932 - val_acc: 0.9978
Epoch 60/150
Epoch 00059: val_loss did not improve
656s - loss: 0.5563 - acc: 0.7634 - val_loss: 0.6932 - val_acc: 0.9970
Epoch 61/150
Epoch 00060: val_loss did not improve
656s - loss: 0.5528 - acc: 0.7709 - val_loss: 0.6932 - val_acc: 0.9926
Epoch 62/150
Epoch 00061: val_loss did not improve
656s - loss: 0.5529 - acc: 0.7710 - val_loss: 0.6934 - val_acc: 0.9640
Epoch 63/150
Epoch 00062: val_loss did not improve
656s - loss: 0.5538 - acc: 0.7694 - val_loss: 0.6932 - val_acc: 0.9987
Epoch 64/150
Epoch 00063: val_loss did not improve
655s - loss: 0.5586 - acc: 0.7527 - val_loss: 0.6932 - val_acc: 0.9983
Epoch 65/150
Epoch 00064: val_loss did not improve
656s - loss: 0.5519 - acc: 0.7725 - val_loss: 0.6932 - val_acc: 0.9978
Epoch 66/150
Epoch 00065: val_loss did not improve
656s - loss: 0.5520 - acc: 0.7752 - val_loss: 0.6932 - val_acc: 0.9918
Epoch 67/150
Epoch 00066: val_loss did not improve
655s - loss: 0.5522 - acc: 0.7722 - val_loss: 0.6932 - val_acc: 0.9952
Epoch 68/150
Epoch 00067: val_loss did not improve
655s - loss: 0.5551 - acc: 0.7656 - val_loss: 0.6931 - val_acc: 0.9996
Epoch 69/150
Epoch 00068: val_loss did not improve
655s - loss: 0.5594 - acc: 0.7515 - val_loss: 0.6932 - val_acc: 0.9909
Epoch 70/150
Epoch 00069: val_loss did not improve
656s - loss: 0.5580 - acc: 0.7539 - val_loss: 0.6932 - val_acc: 0.9900
Epoch 71/150
Epoch 00070: val_loss did not improve
656s - loss: 0.5534 - acc: 0.7709 - val_loss: 0.6933 - val_acc: 0.9822
Epoch 72/150
Epoch 00071: val_loss did not improve
657s - loss: 0.5522 - acc: 0.7737 - val_loss: 0.6932 - val_acc: 0.9952
Epoch 73/150
Epoch 00072: val_loss did not improve
657s - loss: 0.5513 - acc: 0.7757 - val_loss: 0.6932 - val_acc: 0.9905
Epoch 74/150
Epoch 00073: val_loss improved from 0.69315 to 0.69315, saving model to ./test/test_best_weights.h5
657s - loss: 0.5535 - acc: 0.7710 - val_loss: 0.6931 - val_acc: 0.9996
Epoch 75/150
Epoch 00074: val_loss did not improve
657s - loss: 0.5584 - acc: 0.7560 - val_loss: 0.6933 - val_acc: 0.9857
Epoch 76/150
Epoch 00075: val_loss did not improve
656s - loss: 0.5525 - acc: 0.7711 - val_loss: 0.6932 - val_acc: 0.9948
Epoch 77/150
Epoch 00076: val_loss did not improve
655s - loss: 0.5537 - acc: 0.7688 - val_loss: 0.6931 - val_acc: 0.9996
Epoch 78/150
Epoch 00077: val_loss did not improve
655s - loss: 0.5509 - acc: 0.7761 - val_loss: 0.6932 - val_acc: 0.9944
Epoch 79/150
Epoch 00078: val_loss did not improve
656s - loss: 0.5516 - acc: 0.7760 - val_loss: 0.6932 - val_acc: 0.9957
Epoch 80/150
Epoch 00079: val_loss did not improve
655s - loss: 0.5499 - acc: 0.7788 - val_loss: 0.6932 - val_acc: 0.9974
Epoch 81/150
Epoch 00080: val_loss did not improve
655s - loss: 0.5504 - acc: 0.7791 - val_loss: 0.6932 - val_acc: 0.9987
Epoch 82/150
Epoch 00081: val_loss improved from 0.69315 to 0.69315, saving model to ./test/test_best_weights.h5
655s - loss: 0.5541 - acc: 0.7696 - val_loss: 0.6931 - val_acc: 0.9996
Epoch 83/150
Epoch 00082: val_loss did not improve
655s - loss: 0.5568 - acc: 0.7603 - val_loss: 0.6945 - val_acc: 0.8694
Epoch 84/150
Epoch 00083: val_loss did not improve
655s - loss: 0.5520 - acc: 0.7749 - val_loss: 0.6932 - val_acc: 0.9939
Epoch 85/150
Epoch 00084: val_loss did not improve
656s - loss: 0.5505 - acc: 0.7779 - val_loss: 0.6932 - val_acc: 0.9939
Epoch 86/150
Epoch 00085: val_loss did not improve
656s - loss: 0.5536 - acc: 0.7698 - val_loss: 0.6932 - val_acc: 0.9952
Epoch 87/150
Epoch 00086: val_loss did not improve
657s - loss: 0.5506 - acc: 0.7768 - val_loss: 0.6932 - val_acc: 0.9978
Epoch 88/150
Epoch 00087: val_loss did not improve
657s - loss: 0.5498 - acc: 0.7788 - val_loss: 0.6932 - val_acc: 0.9952
Epoch 89/150
Epoch 00088: val_loss did not improve
656s - loss: 0.5508 - acc: 0.7768 - val_loss: 0.6932 - val_acc: 0.9978
Epoch 90/150
Epoch 00089: val_loss did not improve
657s - loss: 0.5498 - acc: 0.7792 - val_loss: 0.6931 - val_acc: 0.9996
Epoch 91/150
Epoch 00090: val_loss did not improve
659s - loss: 0.5497 - acc: 0.7799 - val_loss: 0.6931 - val_acc: 0.9996
Epoch 92/150
Epoch 00091: val_loss did not improve
656s - loss: 0.5507 - acc: 0.7768 - val_loss: 0.6932 - val_acc: 0.9965
Epoch 93/150
Epoch 00092: val_loss did not improve
655s - loss: 0.5505 - acc: 0.7789 - val_loss: 0.6932 - val_acc: 0.9978
Epoch 94/150
Epoch 00093: val_loss did not improve
655s - loss: 0.5498 - acc: 0.7792 - val_loss: 0.6932 - val_acc: 0.9952
Epoch 95/150
Epoch 00094: val_loss did not improve
655s - loss: 0.5503 - acc: 0.7785 - val_loss: 0.6931 - val_acc: 0.9996
Epoch 96/150
Epoch 00095: val_loss improved from 0.69315 to 0.69315, saving model to ./test/test_best_weights.h5
655s - loss: 0.5510 - acc: 0.7778 - val_loss: 0.6931 - val_acc: 0.9996
Epoch 97/150
Epoch 00096: val_loss did not improve
654s - loss: 0.5568 - acc: 0.7598 - val_loss: 0.6931 - val_acc: 0.9996
Epoch 98/150
Epoch 00097: val_loss did not improve
655s - loss: 0.5509 - acc: 0.7780 - val_loss: 0.6932 - val_acc: 0.9952
Epoch 99/150
Epoch 00098: val_loss did not improve
654s - loss: 0.5503 - acc: 0.7766 - val_loss: 0.6932 - val_acc: 0.9952
Epoch 100/150
Epoch 00099: val_loss did not improve
655s - loss: 0.5509 - acc: 0.7763 - val_loss: 0.6932 - val_acc: 0.9970
Epoch 101/150
Epoch 00100: val_loss did not improve
656s - loss: 0.5556 - acc: 0.7671 - val_loss: 0.6932 - val_acc: 0.9991
Epoch 102/150
Epoch 00101: val_loss did not improve
656s - loss: 0.5500 - acc: 0.7801 - val_loss: 0.6932 - val_acc: 0.9974
Epoch 103/150
Epoch 00102: val_loss did not improve
656s - loss: 0.5512 - acc: 0.7748 - val_loss: 0.6932 - val_acc: 0.9926
Epoch 104/150
Epoch 00103: val_loss did not improve
656s - loss: 0.5531 - acc: 0.7692 - val_loss: 0.6931 - val_acc: 0.9996
Epoch 105/150
Traceback (most recent call last):
  File "./src/pelvis_training.py", line 191, in <module>
    model.fit(patches_imgs_train, patches_masks_train, nb_epoch=N_epochs, batch_size=batch_size, verbose=2, shuffle=True, validation_split=0.1, callbacks=[checkpointer])
  File "/home/houda/tensorflow/local/lib/python2.7/site-packages/keras/engine/training.py", line 1598, in fit
    validation_steps=validation_steps)
  File "/home/houda/tensorflow/local/lib/python2.7/site-packages/keras/engine/training.py", line 1183, in _fit_loop
    outs = f(ins_batch)
  File "/home/houda/tensorflow/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py", line 2273, in __call__
    **self.session_kwargs)
  File "/home/houda/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 895, in run
    run_metadata_ptr)
  File "/home/houda/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/houda/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1321, in _do_run
    options, run_metadata)
  File "/home/houda/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1327, in _do_call
    return fn(*args)
  File "/home/houda/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1306, in _run_fn
    status, run_metadata)
KeyboardInterrupt
